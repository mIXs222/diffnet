{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compliant-holder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Modified from https://github.com/PeiJieSun/diffnet/tree/master/diffnet\n",
    "'''\n",
    "import os, sys, shutil\n",
    "sys.path.append(os.path.join(os.getcwd(), 'class'))\n",
    "\n",
    "import pickle\n",
    "\n",
    "from ParserConf import ParserConf\n",
    "from DataUtil import DataUtil\n",
    "from Evaluate import Evaluate\n",
    "from diffnet import diffnet\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #ignore the warnings \n",
    "\n",
    "from Logging import Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'yelp'\n",
    "model_name = 'diffnet'\n",
    "config_path = os.path.join(os.getcwd(), 'conf/%s_%s.ini' % (data_name, model_name))\n",
    "\n",
    "print(config_path)\n",
    "#print('System start to prepare parser config file...')\n",
    "conf = ParserConf(config_path)\n",
    "conf.parserConf()\n",
    "print(conf.topk)\n",
    "\n",
    "#print('System start to load TensorFlow graph...')\n",
    "model = eval(model_name)\n",
    "model = model(conf)\n",
    "\n",
    "#print('System start to load data...')\n",
    "data = DataUtil(conf)\n",
    "evaluate = Evaluate(conf)\n",
    "\n",
    "\n",
    "\n",
    "# train.start(conf, data, model, evaluate)\n",
    "log_dir = os.path.join(os.getcwd(), 'log')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "# define log name \n",
    "log_path = os.path.join(os.getcwd(), 'log/%s_%s.log' % (conf.data_name, conf.model_name))\n",
    "\n",
    "# start to prepare data for training and evaluating\n",
    "# data is a object of DataUtil class\n",
    "data.initializeRankingHandle()\n",
    "# data.train, data.val, ..., are objects of DataModule class\n",
    "# get four DataModule class object\n",
    "d_train, d_val, d_test, d_test_eva = data.train, data.val, data.test, data.test_eva\n",
    "\n",
    "# read postive (true) ratings and generate negative ratings\n",
    "print('System start to load data...')\n",
    "t0 = time()\n",
    "d_train.initializeRankingTrain()\n",
    "d_val.initializeRankingVT()\n",
    "d_test.initializeRankingVT()\n",
    "d_test_eva.initalizeRankingEva()\n",
    "t1 = time()\n",
    "print('Data has been loaded successfully, cost:%.4fs' % (t1 - t0))\n",
    "\n",
    "# prepare model necessary data.\n",
    "# data_dict constains the user-user link/user-item link and score for each link from averaging the numbers\n",
    "data_dict = d_train.prepareModelSupplement(model) \n",
    "model.inputSupply(data_dict) # prepare tf.sparse tensor\n",
    "model.startConstructGraph()\n",
    "\n",
    "# standard tensorflow running environment initialize\n",
    "tf_conf = tf.ConfigProto()\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf_conf.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=tf_conf)\n",
    "sess.run(model.init)\n",
    "\n",
    "if conf.pretrain_flag == 1:\n",
    "    model.saver.restore(sess, conf.pre_model)\n",
    "\n",
    "# set debug_flag=0, doesn't print any results\n",
    "log = Logging(log_path)\n",
    "print()\n",
    "log.record('Following will output the evaluation of the model:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training !!!\n",
    "for epoch in range(1, conf.epochs+1):\n",
    "    # optimize model with training data and compute train loss\n",
    "    tmp_train_loss = []\n",
    "    t0 = time()\n",
    "\n",
    "    #tmp_total_list = []\n",
    "    while d_train.terminal_flag:\n",
    "        d_train.getTrainRankingBatch()\n",
    "        d_train.linkedMap()\n",
    "\n",
    "        train_feed_dict = {}\n",
    "        for (key, value) in model.map_dict['train'].items():\n",
    "            train_feed_dict[key] = d_train.data_dict[value]\n",
    "\n",
    "        [sub_train_loss, _] = sess.run(\\\n",
    "            [model.map_dict['out']['train'], model.opt], feed_dict=train_feed_dict)\n",
    "        tmp_train_loss.append(sub_train_loss)\n",
    "    train_loss = np.mean(tmp_train_loss)\n",
    "    t1 = time()\n",
    "\n",
    "    # compute val loss and test loss\n",
    "    d_val.getVTRankingOneBatch()\n",
    "    d_val.linkedMap()\n",
    "    val_feed_dict = {}\n",
    "    for (key, value) in model.map_dict['val'].items():\n",
    "        val_feed_dict[key] = d_val.data_dict[value]\n",
    "    val_loss = sess.run(model.map_dict['out']['val'], feed_dict=val_feed_dict)\n",
    "\n",
    "    d_test.getVTRankingOneBatch()\n",
    "    d_test.linkedMap()\n",
    "    test_feed_dict = {}\n",
    "    for (key, value) in model.map_dict['test'].items():\n",
    "        test_feed_dict[key] = d_test.data_dict[value]\n",
    "    test_loss = sess.run(model.map_dict['out']['test'], feed_dict=test_feed_dict)\n",
    "    t2 = time()\n",
    "\n",
    "    # start evaluate model performance, hr and ndcg\n",
    "    def getPositivePredictions():\n",
    "        d_test_eva.getEvaPositiveBatch()\n",
    "        d_test_eva.linkedRankingEvaMap()\n",
    "        eva_feed_dict = {}\n",
    "        for (key, value) in model.map_dict['eva'].items():\n",
    "            eva_feed_dict[key] = d_test_eva.data_dict[value]\n",
    "        positive_predictions = sess.run(\n",
    "            model.map_dict['out']['eva'],\n",
    "            feed_dict=eva_feed_dict\n",
    "        )\n",
    "        return positive_predictions\n",
    "\n",
    "    def getNegativePredictions():\n",
    "        negative_predictions = {}\n",
    "        terminal_flag = 1\n",
    "        while terminal_flag:\n",
    "            batch_user_list, terminal_flag = d_test_eva.getEvaRankingBatch()\n",
    "            d_test_eva.linkedRankingEvaMap()\n",
    "            eva_feed_dict = {}\n",
    "            for (key, value) in model.map_dict['eva'].items():\n",
    "                eva_feed_dict[key] = d_test_eva.data_dict[value]\n",
    "            index = 0\n",
    "            tmp_negative_predictions = np.reshape(\n",
    "                sess.run(\n",
    "                    model.map_dict['out']['eva'],\n",
    "                    feed_dict=eva_feed_dict\n",
    "                ),\n",
    "                [-1, conf.num_evaluate])\n",
    "            for u in batch_user_list:\n",
    "                negative_predictions[u] = tmp_negative_predictions[index]\n",
    "                index = index + 1\n",
    "        return negative_predictions\n",
    "\n",
    "\n",
    "    tt2 = time()\n",
    "\n",
    "    index_dict = d_test_eva.eva_index_dict\n",
    "    positive_predictions = getPositivePredictions()\n",
    "    negative_predictions = getNegativePredictions()\n",
    "\n",
    "    d_test_eva.index = 0 # !!!important, prepare for new batch\n",
    "    if epoch == 1 or epoch %10 == 0:\n",
    "        hr, ndcg = evaluate.evaluateRankingPerformance(\\\n",
    "            index_dict, positive_predictions, negative_predictions, conf.topk, conf.num_procs)\n",
    "    tt3 = time()\n",
    "\n",
    "    # print log to console and log_file\n",
    "    log.record('Epoch:%d, compute loss cost:%.4fs, train loss:%.4f, val loss:%.4f, test loss:%.4f' % \\\n",
    "        (epoch, (t2-t0), train_loss, val_loss, test_loss))\n",
    "    log.record('Evaluate cost:%.4fs, hr:%.4f, ndcg:%.4f' % ((tt3-tt2), hr, ndcg))\n",
    "\n",
    "    ## reset train data pointer, and generate new negative data\n",
    "    d_train.generateTrainNegative()\n",
    "\n",
    "pickle.dump(positive_predictions, open(\"pred.p\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
