{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noble-steal",
   "metadata": {},
   "source": [
    "## Yelp dataset in the paper:\n",
    "\n",
    "The data given in the paper is the yelp data and has following files:\n",
    "- `item_vector.npy`/`user_vector.npy`: the feature vectors of the user/item from word2vec (using Gensim)\n",
    "- `yelp.links`: the social graph between the users\n",
    "- `yelp.test.rating`/`yelp.train.rating`/`yelp.val.rating`: the split dataset for user-item rating (10%/80%/10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exciting-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "foster-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"citation/cit-HepTh.txt\"\n",
    "\n",
    "f = open(filename) \n",
    "total_user_list = set()\n",
    "total_item_list = set()\n",
    "hash_data = defaultdict(int)\n",
    "\n",
    "for _, line in enumerate(f):\n",
    "    arr = line.split(\"\\t\")\n",
    "    hash_data[(int(arr[0]), int(arr[1]))] = 1\n",
    "    total_user_list.add(int(arr[0]))\n",
    "    total_item_list.add(int(arr[1]))\n",
    "\n",
    "total_user_list = list(total_user_list)\n",
    "total_item_list = list(total_item_list)\n",
    "hash_data = hash_data\n",
    "\n",
    "mapping_user_idx = {user:idx for idx,user in enumerate(total_user_list)}\n",
    "mapping_item_idx = {item:idx for idx,item in enumerate(total_item_list)}\n",
    "\n",
    "graph = np.zeros((len(total_user_list), len(total_item_list)))\n",
    "for user, item in hash_data:\n",
    "    graph[mapping_user_idx[user]][mapping_item_idx[item]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "vocal-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Free embedding from the non-negative matrix factorization\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=150, init='nndsvd')\n",
    "W = model.fit_transform(graph)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "unique-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./citation/user_vector.npy\", W)\n",
    "np.save(\"./citation/item_vector.npy\", H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "conceptual-identification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25059, 23180)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "naughty-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"citation/cit-HepTh.txt\"\n",
    "\n",
    "f = open(filename)\n",
    "f_to = open(\"citation/citation.links\", \"a\")\n",
    "total_data = []\n",
    "\n",
    "for _, line in enumerate(f):\n",
    "    arr = line.strip().split(\"\\t\")\n",
    "    total_data.append(arr)\n",
    "    f_to.write(arr[0] + \"\\t\" + arr[1] + \"\\t\" + \"1\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "complicated-proxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352807"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "stretch-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(total_data)\n",
    "train_data = total_data[:282296]\n",
    "val_data = total_data[282296:317583]\n",
    "test_data = total_data[317583:]\n",
    "\n",
    "f_train = open(\"citation/citation.train.rating\", \"a\")\n",
    "f_val = open(\"citation/citation.val.rating\", \"a\")\n",
    "f_test = open(\"citation/citation.test.rating\", \"a\")\n",
    "\n",
    "for _, arr in enumerate(train_data):\n",
    "    f_train.write(arr[0] + \"\\t\" + arr[1] + \"\\t\" + \"1\" + \"\\n\")\n",
    "for _, arr in enumerate(val_data):\n",
    "    f_val.write(arr[0] + \"\\t\" + arr[1] + \"\\t\" + \"1\" + \"\\n\")\n",
    "for _, arr in enumerate(test_data):\n",
    "    f_test.write(arr[0] + \"\\t\" + arr[1] + \"\\t\" + \"1\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-client",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
